{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q2-3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6MlHCEAdZPy1","colab_type":"text"},"source":["**Initial step:** Please try to put the extracted CamVid folder in your Google Drive!\n","So now you could mount your data to this ipynb!"]},{"cell_type":"code","metadata":{"id":"UGAXY5HMYjzL","colab_type":"code","outputId":"e1342b69-351a-4982-f601-8582593c0ea5","executionInfo":{"status":"ok","timestamp":1577376097554,"user_tz":-480,"elapsed":976,"user":{"displayName":"楊子儀","photoUrl":"","userId":"11501322789249152564"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wTBYCMcpZoA8","colab_type":"code","outputId":"56af9042-d4d4-4293-a9bf-50c495bc47ef","executionInfo":{"status":"ok","timestamp":1577376101419,"user_tz":-480,"elapsed":4811,"user":{"displayName":"楊子儀","photoUrl":"","userId":"11501322789249152564"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# if you mount Google drive correctly, the following commands should be able to executed correctly\n","!ls /content/drive/\n","%cd \"/content/drive/My Drive\"\n","%cd \"CamVid\"\n","\n","!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["'My Drive'  'Shared drives'\n","/content/drive/My Drive\n","/content/drive/My Drive/CamVid\n","result_comparision  train  trainannot  train.csv  val  valannot  val.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pfWmPZKyZ8gA","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import utils\n","import torchvision\n","from torchvision import models\n","from torchvision.models.vgg import VGG\n","import random\n","\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import time\n","import sys\n","import os\n","from os import path\n","\n","from PIL import Image\n","import pandas as pd\n","from torchvision.models.vgg import VGG"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YMzL2KhcaI9u","colab_type":"code","outputId":"14c07685-fab9-454b-9546-32970c4cd3de","executionInfo":{"status":"ok","timestamp":1577376101670,"user_tz":-480,"elapsed":5017,"user":{"displayName":"楊子儀","photoUrl":"","userId":"11501322789249152564"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["\n","root_dir   = \"/content/drive/My Drive/CamVid/\"\n","train_file = os.path.join(root_dir, \"train.csv\")\n","val_file   = os.path.join(root_dir, \"val.csv\")\n","\n","print(\"training csv exits:{}\".format(path.exists(train_file)))\n","print(\"validation csv exits:{}\".format(path.exists(val_file)))\n","\n","# the folder to save results for comparison\n","folder_to_save_validation_result = '/content/drive/My Drive/CamVid/result_comparision/' \n","\n","if os.path.isdir(folder_to_save_validation_result) == False:\n","    os.mkdir(folder_to_save_validation_result)\n","\n","\n","# the number of segmentation classes\n","num_class = 11 # 32 for original CamVid\n","means     = np.array([103.939, 116.779, 123.68]) / 255. # mean of three channels in the order of BGR\n","\n","h, w      = 256, 256\n","train_h = 256\n","train_w = 256\n","val_h = 256\n","val_w = 256\n","\n","## parameters for Solver-Adam in this example\n","batch_size = 6 #\n","epochs     = 20 # don't try to improve the performance by simply increasing the training epochs or iterations\n","lr         = 1e-4    # achieved besty results \n","step_size  = 100 # Won't work when epochs <=100\n","gamma      = 0.5 # \n","#\n","\n","## index for validation images\n","global_index = 0\n","\n","# pixel accuracy and mIOU list \n","pixel_acc_list = []\n","mIOU_list = []\n","\n","use_gpu = torch.cuda.is_available()\n","num_gpu = list(range(torch.cuda.device_count()))\n","\n","class CamVidDataset(Dataset):\n","\n","    def __init__(self, csv_file, phase, n_class=num_class, crop=True, flip_rate=0.5):\n","        self.data      = pd.read_csv(csv_file)\n","        self.means     = means\n","        self.n_class   = n_class\n","        self.flip_rate = flip_rate       \n","\n","        self.resize_h = h\n","        self.resize_w = w        \n","        \n","        if phase == 'train':\n","            self.new_h = train_h\n","            self.new_w = train_w\n","            self.crop = crop\n","        elif phase == 'val':\n","            self.flip_rate = 0.\n","            self.crop = False # False\n","            self.new_h = val_h\n","            self.new_w = val_w\n","\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        # print(\"aaaaaaaaaaaa\")\n","\n","        img_name   = self.data.iloc[idx, 0]                \n","        img_name = root_dir  + img_name                        \n","        img = Image.open(img_name).convert('RGB')  \n","\n","        label_name = self.data.iloc[idx, 1]        \n","        label_name = root_dir  + label_name                       \n","        label_image = Image.open(label_name)\n","        label = np.asarray(label_image)\n","\n","        # In training mode, the crop strategy is random-shift crop.\n","        # In validation model, it is center crop.\n","        if self.crop:            \n","            w, h = img.size\n","            A_x_offset = np.int32(np.random.randint(0, w - self.new_w + 1, 1))[0]\n","            A_y_offset = np.int32(np.random.randint(0, h - self.new_h + 1, 1))[0]\n","\n","            img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n","            label_image = label_image.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n","        else:            \n","            w, h = img.size\n","            A_x_offset = int((w - self.new_w)/2)\n","            A_y_offset = int((h - self.new_h)/2)\n","            \n","            img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n","            label_image = label_image.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n","\n","            label_image_h, label_image_w = label_image.size\n","\n","        # we could try to revise the values in label for reducing the number of segmentation classes\n","        label = np.array(label_image)\n","\n","        label = np.where( (label<8) & (label>0), 1, label)\n","        label = np.where(label>=8, 2, label)\n","\n","        # print(\"hhhee\",label,\"sss\")          \n","\n","        if random.random() < self.flip_rate:\n","            img   = np.fliplr(img)\n","            label = np.fliplr(label)\n","        \n","        # reduce mean in terms of BGR\n","        img = np.transpose(img, (2, 0, 1)) / 255.\n","        img[0] -= self.means[0]\n","        img[1] -= self.means[1]\n","        img[2] -= self.means[2]\n","\n","        # convert to tensor\n","        img = torch.from_numpy(img.copy()).float()\n","        label = torch.from_numpy(label.copy()).long()\n","\n","        # create one-hot encoding\n","        h, w = label.size()\n","        target = torch.zeros(self.n_class, h, w)\n","        for c in range(self.n_class):\n","            target[c][label == c] = 1\n","\n","        # print(target)\n","        # print(\"-------------\")\n","        # print(label)\n","\n","        sample = {'X': img, 'Y': target, 'l': label}\n","\n","        return sample\n","\n","\n","train_data = CamVidDataset(csv_file=train_file, phase='train')\n","\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=8)\n","\n","val_data = CamVidDataset(csv_file=val_file, phase='val', flip_rate=0)\n","val_loader = DataLoader(val_data, batch_size=1, num_workers=8)\n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["training csv exits:True\n","validation csv exits:True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nmWXVHiUi9A9","colab_type":"code","colab":{}},"source":["# train_data[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4h-a5moWhLhF","colab_type":"code","outputId":"acf6d550-60c2-4319-f448-46637fa72837","executionInfo":{"status":"ok","timestamp":1577376108297,"user_tz":-480,"elapsed":11611,"user":{"displayName":"楊子儀","photoUrl":"","userId":"11501322789249152564"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# cropped version from https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n","cfg = {\n","    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n","    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n","}\n","\n","ranges = {\n","    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n","    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n","    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n","    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n","}\n","\n","def make_layers(cfg, batch_norm=False):\n","    layers = []\n","    in_channels = 3\n","    for v in cfg:\n","        if v == 'M':\n","            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","        else:\n","            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n","            if batch_norm:\n","                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n","            else:\n","                layers += [conv2d, nn.ReLU(inplace=True)]\n","            in_channels = v\n","    return nn.Sequential(*layers)\n","\n","class VGGNet(VGG):\n","    def __init__(self, pretrained=True, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n","        super().__init__(make_layers(cfg[model]))\n","        self.ranges = ranges[model]\n","\n","        if pretrained:            \n","            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n","\n","        if not requires_grad:\n","            for param in super().parameters():\n","                param.requires_grad = False\n","\n","        if remove_fc:  # delete redundant fully-connected layer params, can save memory\n","            del self.classifier\n","\n","        if show_params:\n","            for name, param in self.named_parameters():\n","                print(name, param.size())\n","\n","    def forward(self, x):\n","        output = {}\n","\n","        # get the output of each maxpooling layer (5 maxpool in VGG net)\n","        for idx in range(len(self.ranges)):\n","            for layer in range(self.ranges[idx][0], self.ranges[idx][1]):\n","                x = self.features[layer](x)\n","            output[\"x%d\"%(idx+1)] = x\n","\n","        return output\n","\n","class FCN8s(nn.Module):\n","    #Ref: https://towardsdatascience.com/review-fcn-semantic-segmentation-eb8c9b50d2d1\n","    #The layer description is accordance with the above fiture instead of the original paper. Alex 2019/12/03 \n","    def __init__(self, pretrained_net, n_class):\n","        super().__init__()\n","        self.n_class = n_class\n","        self.pretrained_net = pretrained_net\n","        self.relu    = nn.ReLU(inplace=True)\n","        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.bn1     = nn.BatchNorm2d(512)\n","        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.bn2     = nn.BatchNorm2d(256)\n","        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.bn3     = nn.BatchNorm2d(128)\n","        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.bn4     = nn.BatchNorm2d(64)\n","        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n","        self.bn5     = nn.BatchNorm2d(32)\n","        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n","\n","    def forward(self, x):\n","        output = self.pretrained_net(x)\n","        # print(output)\n","\n","        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n","        x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n","        x3 = output['x3']  # size=(N, 256, x.H/8,  x.W/8)\n","\n","        ## FCN8\n","        score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n","        score = self.bn1(score + x4)                      # element-wise add, size=(N, 512, x.H/16, x.W/16)                      \n","        score = self.relu(self.deconv2(score))            # size=(N, 256, x.H/8, x.W/8)\n","        score = self.bn2(score + x3)                      # element-wise add, size=(N, 256, x.H/8, x.W/8)           \n","        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n","        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n","        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n","        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n","\n","        # ## FCN32\n","        # score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n","        # score = self.bn1(score)                           # element-wise add, size=(N, 512, x.H/16, x.W/16)                      \n","        # score = self.relu(self.deconv2(score))            # size=(N, 256, x.H/8, x.W/8)\n","        # score = self.bn2(score)                           # element-wise add, size=(N, 256, x.H/8, x.W/8)\n","        # score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n","        # score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n","        # score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n","        # score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n","\n","        return score  # size=(N, n_class, x.H/1, x.W/1)\n","\n","# load pretrained weights and define FCN8s\n","vgg_model = VGGNet(requires_grad=True, remove_fc=True)\n","fcn_model = FCN8s(pretrained_net=vgg_model, n_class=num_class)\n","\n","ts = time.time()\n","vgg_model = vgg_model.cuda()\n","fcn_model = fcn_model.cuda()\n","fcn_model = nn.DataParallel(fcn_model, device_ids=num_gpu)\n","print(\"Finish cuda loading, time elapsed {}\".format(time.time() - ts))\n","\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(fcn_model.parameters(), lr=lr)\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)  "],"execution_count":6,"outputs":[{"output_type":"stream","text":["Finish cuda loading, time elapsed 2.6940948963165283\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lUjPeffKbm36","colab_type":"code","colab":{}},"source":["def train():\n","    for epoch in range(epochs):\n","        scheduler.step()\n","\n","        ts = time.time()\n","        for iter, batch in enumerate(train_loader):\n","            optimizer.zero_grad()\n","\n","            if use_gpu:\n","                inputs = Variable(batch['X'].cuda())\n","                labels = Variable(batch['Y'].cuda())\n","            else:\n","                inputs, labels = Variable(batch['X']), Variable(batch['Y'])\n","\n","            outputs = fcn_model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            if iter % 10 == 0:\n","                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.data.item()))\n","        \n","        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n","        \n","\n","        val(epoch)\n","        \n","    highest_pixel_acc = max(pixel_acc_list)\n","    highest_mIOU = max(mIOU_list)        \n","    \n","    highest_pixel_acc_epoch = pixel_acc_list.index(highest_pixel_acc)\n","    highest_mIOU_epoch = mIOU_list.index(highest_mIOU)\n","    \n","    print(\"The highest mIOU is {} and is achieved at epoch-{}\".format(highest_mIOU, highest_mIOU_epoch))\n","    print(\"The highest pixel accuracy  is {} and is achieved at epoch-{}\".format(highest_pixel_acc, highest_pixel_acc_epoch))\n","    \n","\n","\n","\n","\n","def save_result_comparison(input_np, output_np):\n","    means     = np.array([103.939, 116.779, 123.68]) / 255.\n","    \n","    global global_index\n","    \n","    original_im_RGB = np.zeros((256,256,3))    \n","    original_im_RGB[:,:,0] = input_np[0,0,:,:]    \n","    original_im_RGB[:,:,1] = input_np[0,1,:,:]\n","    original_im_RGB[:,:,2] = input_np[0,2,:,:]\n","        \n","    original_im_RGB[:,:,0] = original_im_RGB[:,:,0] + means[0]\n","    original_im_RGB[:,:,1] = original_im_RGB[:,:,1] + means[1]\n","    original_im_RGB[:,:,2] = original_im_RGB[:,:,2] + means[2]\n","        \n","    original_im_RGB[:,:,0] = original_im_RGB[:,:,0]*255.0\n","    original_im_RGB[:,:,1] = original_im_RGB[:,:,1]*255.0\n","    original_im_RGB[:,:,2] = original_im_RGB[:,:,2]*255.0\n","    \n","    im_seg_RGB = np.zeros((256,256,3))\n","\n","    # the following version is designed for 11-class version and could still work if the number of classes is fewer.\n","    for i in range(256):\n","        for j in range(256):\n","            if output_np[i,j] == 0:\n","                im_seg_RGB[i,j,:] = [128, 128, 128]\n","            elif output_np[i,j] == 1:  \n","                im_seg_RGB[i,j,:] = [128, 0, 0]\n","            elif output_np[i,j] == 2:  \n","                im_seg_RGB[i,j,:] = [192, 192, 128]    \n","            elif output_np[i,j] == 3:  \n","                im_seg_RGB[i,j,:] = [128, 64, 128]    \n","            elif output_np[i,j] == 4:  \n","                im_seg_RGB[i,j,:] = [0, 0, 192]    \n","            elif output_np[i,j] == 5:  \n","                im_seg_RGB[i,j,:] = [128, 128, 0]    \n","            elif output_np[i,j] == 6:  \n","                im_seg_RGB[i,j,:] = [192, 128, 128]    \n","            elif output_np[i,j] == 7:  \n","                im_seg_RGB[i,j,:] = [64, 64, 128]    \n","            elif output_np[i,j] == 8:  \n","                im_seg_RGB[i,j,:] = [64, 0, 128]    \n","            elif output_np[i,j] == 9:  \n","                im_seg_RGB[i,j,:] = [64, 64, 0]    \n","            elif output_np[i,j] == 10:  \n","                im_seg_RGB[i,j,:] = [0, 128, 192]    \n","                    \n","    # horizontally stack original image and its corresponding segmentation results     \n","    hstack_image = np.hstack((original_im_RGB, im_seg_RGB))             \n","    new_im = Image.fromarray(np.uint8(hstack_image))\n","    \n","    file_name = folder_to_save_validation_result + str(global_index) + '.jpg'\n","        \n","    global_index = global_index + 1\n","        \n","    new_im.save(file_name)       "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7cK6h9vkbf7","colab_type":"code","outputId":"ab9c471e-a3df-4cce-d4e0-c2fdd4a8bec7","executionInfo":{"status":"ok","timestamp":1577376471689,"user_tz":-480,"elapsed":374947,"user":{"displayName":"楊子儀","photoUrl":"","userId":"11501322789249152564"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["def val(epoch):\n","    fcn_model.eval()\n","    total_ious = []\n","    pixel_accs = []\n","                    \n","    \n","    for iter, batch in enumerate(val_loader): ## batch is 1 in this case\n","        if use_gpu:\n","            inputs = Variable(batch['X'].cuda())\n","        else:\n","            inputs = Variable(batch['X'])        \n","\n","        output = fcn_model(inputs)                                \n","        \n","        # only save the 1st image for comparison\n","        if iter == 0:\n","            print('---------iter={}'.format(iter))\n","            # generate images\n","            images = output.data.max(1)[1].cpu().numpy()[:,:,:]\n","            image = images[0,:,:]        \n","            save_result_comparison(batch['X'], image)\n","                            \n","        output = output.data.cpu().numpy()\n","\n","        N, _, h, w = output.shape                \n","        pred = output.transpose(0, 2, 3, 1).reshape(-1, num_class).argmax(axis=1).reshape(N, h, w)        \n","        target = batch['l'].cpu().numpy().reshape(N, h, w)\n","\n","        for p, t in zip(pred, target):\n","            total_ious.append(iou(p, t))\n","            pixel_accs.append(pixel_acc(p, t))\n","\n","    # Calculate average IoU\n","    total_ious = np.array(total_ious).T  # n_class * val_len\n","    ious = np.nanmean(total_ious, axis=1)\n","    pixel_accs = np.array(pixel_accs).mean()\n","    print(\"epoch{}, pix_acc: {}, meanIoU: {}, IoUs: {}\".format(epoch, pixel_accs, np.nanmean(ious), ious))\n","    \n","    global pixel_acc_list\n","    global mIOU_list\n","    \n","    pixel_acc_list.append(pixel_accs)\n","    mIOU_list.append(np.nanmean(ious))\n","\n","\n","# borrow functions and modify it from https://github.com/Kaixhin/FCN-semantic-segmentation/blob/master/main.py\n","# Calculates class intersections over unions\n","def iou(pred, target):\n","    ious = []\n","    for cls in range(num_class):\n","        pred_inds = pred == cls\n","        target_inds = target == cls\n","        intersection = pred_inds[target_inds].sum()\n","        union = pred_inds.sum() + target_inds.sum() - intersection\n","        if union == 0:\n","            ious.append(float('nan'))  # if there is no ground truth, do not include in evaluation\n","        else:\n","            ious.append(float(intersection) / max(union, 1))\n","        # print(\"cls\", cls, pred_inds.sum(), target_inds.sum(), intersection, float(intersection) / max(union, 1))\n","    return ious\n","\n","\n","def pixel_acc(pred, target):\n","    correct = (pred == target).sum()\n","    total   = (target == target).sum()\n","    return correct / total\n","\n","\n","## perform training and validation\n","val(0)  # show the accuracy before training\n","train()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["---------iter=0\n","epoch0, pix_acc: 0.003495941162109375, meanIoU: 0.0004765532046581862, IoUs: [4.13408170e-04 4.29096412e-03 6.11597596e-05 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00            nan 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: RuntimeWarning: Mean of empty slice\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["epoch0, iter0, loss: 0.6901606917381287\n","epoch0, iter10, loss: 0.681598424911499\n","epoch0, iter20, loss: 0.6022650003433228\n","epoch0, iter30, loss: 0.4536571800708771\n","epoch0, iter40, loss: 0.32620200514793396\n","epoch0, iter50, loss: 0.25459223985671997\n","epoch0, iter60, loss: 0.18649998307228088\n","Finish epoch 0, time elapsed 14.273701906204224\n","---------iter=0\n","epoch0, pix_acc: 0.7998225402832031, meanIoU: 0.13372792471085976, IoUs: [0.         0.80000046 0.00236709        nan 0.                nan\n","        nan 0.         0.                nan        nan]\n","epoch1, iter0, loss: 0.17496415972709656\n","epoch1, iter10, loss: 0.14880137145519257\n","epoch1, iter20, loss: 0.1312919408082962\n","epoch1, iter30, loss: 0.1167745515704155\n","epoch1, iter40, loss: 0.11890824884176254\n","epoch1, iter50, loss: 0.12019829452037811\n","epoch1, iter60, loss: 0.12309177219867706\n","Finish epoch 1, time elapsed 14.239740133285522\n","---------iter=0\n","epoch1, pix_acc: 0.8033155822753906, meanIoU: 0.20673110947114523, IoUs: [7.06856250e-04 8.04137243e-01 2.20803384e-02            nan\n"," 0.00000000e+00            nan            nan            nan\n","            nan            nan            nan]\n","epoch2, iter0, loss: 0.13371972739696503\n","epoch2, iter10, loss: 0.09147308021783829\n","epoch2, iter20, loss: 0.08412185311317444\n","epoch2, iter30, loss: 0.07932117581367493\n","epoch2, iter40, loss: 0.0601959191262722\n","epoch2, iter50, loss: 0.06586381793022156\n","epoch2, iter60, loss: 0.06671265512704849\n","Finish epoch 2, time elapsed 14.274737358093262\n","---------iter=0\n","epoch2, pix_acc: 0.8990412902832031, meanIoU: 0.45287277324762343, IoUs: [0.84075098 0.88669628 0.08404383        nan 0.                nan\n","        nan        nan        nan        nan        nan]\n","epoch3, iter0, loss: 0.04611937329173088\n","epoch3, iter10, loss: 0.05033034458756447\n","epoch3, iter20, loss: 0.05327773094177246\n","epoch3, iter30, loss: 0.05872463062405586\n","epoch3, iter40, loss: 0.05529715120792389\n","epoch3, iter50, loss: 0.036143165081739426\n","epoch3, iter60, loss: 0.051204580813646317\n","Finish epoch 3, time elapsed 14.342078685760498\n","---------iter=0\n","epoch3, pix_acc: 0.9110379028320312, meanIoU: 0.4785806776629579, IoUs: [0.88468283 0.89965071 0.12998917        nan 0.                nan\n","        nan        nan        nan        nan        nan]\n","epoch4, iter0, loss: 0.045325569808483124\n","epoch4, iter10, loss: 0.04715021699666977\n","epoch4, iter20, loss: 0.02987564355134964\n","epoch4, iter30, loss: 0.038598593324422836\n","epoch4, iter40, loss: 0.04341413825750351\n","epoch4, iter50, loss: 0.03874276578426361\n","epoch4, iter60, loss: 0.04126996174454689\n","Finish epoch 4, time elapsed 14.406187295913696\n","---------iter=0\n","epoch4, pix_acc: 0.9235154724121094, meanIoU: 0.5543909171148741, IoUs: [0.88226085 0.91030258 0.42500024        nan 0.                nan\n","        nan        nan        nan        nan        nan]\n","epoch5, iter0, loss: 0.03770194202661514\n","epoch5, iter10, loss: 0.02911379002034664\n","epoch5, iter20, loss: 0.0401635468006134\n","epoch5, iter30, loss: 0.0467648021876812\n","epoch5, iter40, loss: 0.033562563359737396\n","epoch5, iter50, loss: 0.031502798199653625\n","epoch5, iter60, loss: 0.03273133188486099\n","Finish epoch 5, time elapsed 14.407711505889893\n","---------iter=0\n","epoch5, pix_acc: 0.9068354797363282, meanIoU: 0.5620478207862096, IoUs: [0.89717116 0.88735331 0.46366681        nan 0.                nan\n","        nan        nan        nan        nan        nan]\n","epoch6, iter0, loss: 0.04131212458014488\n","epoch6, iter10, loss: 0.04951491206884384\n","epoch6, iter20, loss: 0.038865964859724045\n","epoch6, iter30, loss: 0.030968796461820602\n","epoch6, iter40, loss: 0.03080950491130352\n","epoch6, iter50, loss: 0.029793620109558105\n","epoch6, iter60, loss: 0.03565729036927223\n","Finish epoch 6, time elapsed 14.5621018409729\n","---------iter=0\n","epoch6, pix_acc: 0.9090428161621094, meanIoU: 0.5661800178911451, IoUs: [0.90309328 0.89096974 0.47065706        nan 0.                nan\n","        nan        nan        nan        nan        nan]\n","epoch7, iter0, loss: 0.03512619435787201\n","epoch7, iter10, loss: 0.03063245676457882\n","epoch7, iter20, loss: 0.035246871411800385\n","epoch7, iter30, loss: 0.035527098923921585\n","epoch7, iter40, loss: 0.035404305905103683\n","epoch7, iter50, loss: 0.029060952365398407\n","epoch7, iter60, loss: 0.03890901803970337\n","Finish epoch 7, time elapsed 14.595078229904175\n","---------iter=0\n","epoch7, pix_acc: 0.9403956604003906, meanIoU: 0.7831507458426633, IoUs: [0.9047974  0.92981297 0.51484187        nan        nan        nan\n","        nan        nan        nan        nan        nan]\n","epoch8, iter0, loss: 0.040078554302453995\n","epoch8, iter10, loss: 0.02464609593153\n","epoch8, iter20, loss: 0.028025031089782715\n","epoch8, iter30, loss: 0.030698660761117935\n","epoch8, iter40, loss: 0.03469643369317055\n","epoch8, iter50, loss: 0.03286127746105194\n","epoch8, iter60, loss: 0.030491650104522705\n","Finish epoch 8, time elapsed 14.588128328323364\n","---------iter=0\n","epoch8, pix_acc: 0.9369036865234375, meanIoU: 0.7803545194859529, IoUs: [0.90091505 0.92507999 0.51506852        nan        nan        nan\n","        nan        nan        nan        nan        nan]\n","epoch9, iter0, loss: 0.04349169135093689\n","epoch9, iter10, loss: 0.03090985305607319\n","epoch9, iter20, loss: 0.04496878758072853\n","epoch9, iter30, loss: 0.035714611411094666\n","epoch9, iter40, loss: 0.030053487047553062\n","epoch9, iter50, loss: 0.035503268241882324\n","epoch9, iter60, loss: 0.038106802850961685\n","Finish epoch 9, time elapsed 14.66635775566101\n","---------iter=0\n","epoch9, pix_acc: 0.9331843566894531, meanIoU: 0.7772280924123045, IoUs: [0.90777746 0.92138649 0.50252032        nan        nan        nan\n","        nan        nan        nan        nan        nan]\n","epoch10, iter0, loss: 0.021170491352677345\n","epoch10, iter10, loss: 0.03570341318845749\n","epoch10, iter20, loss: 0.030676625669002533\n","epoch10, iter30, loss: 0.03170260041952133\n","epoch10, iter40, loss: 0.030015472322702408\n","epoch10, iter50, loss: 0.03500613942742348\n","epoch10, iter60, loss: 0.029789524152874947\n","Finish epoch 10, time elapsed 14.716944932937622\n","---------iter=0\n","epoch10, pix_acc: 0.9252529907226562, meanIoU: 0.7692423846976356, IoUs: [0.90929971 0.91166936 0.48675807        nan        nan        nan\n","        nan        nan        nan        nan        nan]\n","epoch11, iter0, loss: 0.030429769307374954\n","epoch11, iter10, loss: 0.024648532271385193\n","epoch11, iter20, loss: 0.04270482063293457\n","epoch11, iter30, loss: 0.031203508377075195\n","epoch11, iter40, loss: 0.024687539786100388\n","epoch11, iter50, loss: 0.024238107725977898\n","epoch11, iter60, loss: 0.02950349822640419\n","Finish epoch 11, time elapsed 14.860326766967773\n","---------iter=0\n","epoch11, pix_acc: 0.9281672668457032, meanIoU: 0.7872255323454532, IoUs: [0.91186012 0.91401446 0.53580202        nan        nan        nan\n","        nan        nan        nan        nan        nan]\n","epoch12, iter0, loss: 0.02760632149875164\n","epoch12, iter10, loss: 0.03779134899377823\n","epoch12, iter20, loss: 0.02999911643564701\n","epoch12, iter30, loss: 0.023841453716158867\n","epoch12, iter40, loss: 0.03708896040916443\n","epoch12, iter50, loss: 0.029193906113505363\n","epoch12, iter60, loss: 0.02821408398449421\n","Finish epoch 12, time elapsed 14.81045389175415\n","---------iter=0\n","epoch12, pix_acc: 0.9357403564453125, meanIoU: 0.7910360717038557, IoUs: [0.91240761 0.92401499 0.53668562        nan        nan        nan\n","        nan        nan        nan        nan        nan]\n","epoch13, iter0, loss: 0.01664283499121666\n","epoch13, iter10, loss: 0.036172159016132355\n","epoch13, iter20, loss: 0.02279764600098133\n","epoch13, iter30, loss: 0.03646787256002426\n","epoch13, iter40, loss: 0.028468644246459007\n","epoch13, iter50, loss: 0.039451904594898224\n","epoch13, iter60, loss: 0.025071199983358383\n","Finish epoch 13, time elapsed 14.908736944198608\n","---------iter=0\n","epoch13, pix_acc: 0.9360075378417969, meanIoU: 0.8004481223783438, IoUs: [0.91469195 0.92366474 0.56298767        nan        nan        nan\n","        nan        nan        nan        nan        nan]\n","epoch14, iter0, loss: 0.024163546040654182\n","epoch14, iter10, loss: 0.03074745088815689\n","epoch14, iter20, loss: 0.034940123558044434\n","epoch14, iter30, loss: 0.03777637705206871\n","epoch14, iter40, loss: 0.023403670638799667\n","epoch14, iter50, loss: 0.03529881685972214\n","epoch14, iter60, loss: 0.020939476788043976\n","Finish epoch 14, time elapsed 14.877838611602783\n","---------iter=0\n","epoch14, pix_acc: 0.9437709045410156, meanIoU: 0.810407783204596, IoUs: [0.91182967 0.93318823 0.58620544        nan        nan        nan\n","        nan        nan        nan        nan        nan]\n","epoch15, iter0, loss: 0.019623665139079094\n","epoch15, iter10, loss: 0.0385524146258831\n","epoch15, iter20, loss: 0.02613254077732563\n","epoch15, iter30, loss: 0.018735235556960106\n","epoch15, iter40, loss: 0.03151346743106842\n","epoch15, iter50, loss: 0.024109894409775734\n","epoch15, iter60, loss: 0.025002075359225273\n","Finish epoch 15, time elapsed 14.890098810195923\n","---------iter=0\n","epoch15, pix_acc: 0.9456251525878906, meanIoU: 0.8166192326635414, IoUs: [0.91124941 0.9349527  0.6036556         nan        nan        nan\n","        nan        nan        nan        nan        nan]\n","epoch16, iter0, loss: 0.0248276237398386\n","epoch16, iter10, loss: 0.023838086053729057\n","epoch16, iter20, loss: 0.03266588971018791\n","epoch16, iter30, loss: 0.02236676588654518\n","epoch16, iter40, loss: 0.02627803385257721\n","epoch16, iter50, loss: 0.026462340727448463\n","epoch16, iter60, loss: 0.025298133492469788\n","Finish epoch 16, time elapsed 14.860560655593872\n","---------iter=0\n","epoch16, pix_acc: 0.9455001831054688, meanIoU: 0.8088822587290604, IoUs: [0.91426227 0.93548336 0.57690115        nan        nan        nan\n","        nan        nan        nan        nan        nan]\n","epoch17, iter0, loss: 0.02570604905486107\n","epoch17, iter10, loss: 0.028788302093744278\n","epoch17, iter20, loss: 0.028056016191840172\n","epoch17, iter30, loss: 0.03257060423493385\n","epoch17, iter40, loss: 0.02329188399016857\n","epoch17, iter50, loss: 0.025170817971229553\n","epoch17, iter60, loss: 0.019989555701613426\n","Finish epoch 17, time elapsed 14.909405946731567\n","---------iter=0\n","epoch17, pix_acc: 0.9321479797363281, meanIoU: 0.7953705287298486, IoUs: [0.91637117 0.91926977 0.55047065        nan        nan        nan\n","        nan        nan        nan        nan        nan]\n","epoch18, iter0, loss: 0.02162804640829563\n","epoch18, iter10, loss: 0.020278453826904297\n","epoch18, iter20, loss: 0.01874382793903351\n","epoch18, iter30, loss: 0.026160186156630516\n","epoch18, iter40, loss: 0.02286810614168644\n","epoch18, iter50, loss: 0.026706291362643242\n","epoch18, iter60, loss: 0.020517701283097267\n","Finish epoch 18, time elapsed 14.871832370758057\n","---------iter=0\n","epoch18, pix_acc: 0.9451512145996094, meanIoU: 0.8170541870934019, IoUs: [0.91518756 0.93484101 0.60113399        nan        nan        nan\n","        nan        nan        nan        nan        nan]\n","epoch19, iter0, loss: 0.023538602516055107\n","epoch19, iter10, loss: 0.021410387009382248\n","epoch19, iter20, loss: 0.01696276292204857\n","epoch19, iter30, loss: 0.0481082983314991\n","epoch19, iter40, loss: 0.02220882475376129\n","epoch19, iter50, loss: 0.02421646937727928\n","epoch19, iter60, loss: 0.025727415457367897\n","Finish epoch 19, time elapsed 14.99652647972107\n","---------iter=0\n","epoch19, pix_acc: 0.9357571411132812, meanIoU: 0.8005558799734076, IoUs: [0.91164837 0.92343933 0.56657994        nan        nan        nan\n","        nan        nan        nan        nan        nan]\n","The highest mIOU is 0.8170541870934019 and is achieved at epoch-19\n","The highest pixel accuracy  is 0.9456251525878906 and is achieved at epoch-16\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GA8VUYdHstYy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}